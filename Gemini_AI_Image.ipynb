{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Y_TWs4XQ7fxhDwglN0-roNcM8YiCsGFr",
      "authorship_tag": "ABX9TyMSuMScS2azgdloGZOkI2hU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopireddy99/Gemini_AI-/blob/main/Gemini_AI_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q \"google-generativeai>=0.7.2\""
      ],
      "metadata": {
        "id": "yXU06nQqfzjP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i-TwV5bRZru0"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_I = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_I)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "KrEnw8CNZutt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import google.generativeai as genai # Import google.generativeai and assign it to genai\n",
        "\n",
        "iimg = PIL.Image.open('/content/drive/MyDrive/data/image1.jpg')\n",
        "img = iimg\n",
        "model = genai.GenerativeModel('models/gemini-2.0-flash') # Now genai is defined and can be used.\n",
        "response = model.generate_content([\"write a short, engaging blog post based on this picture.It should include a description of the meal in the photo and talk about my journey\",img],stream=True)\n",
        "\n",
        "response.resolve()\n",
        "\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "DB-5-DzDaR4J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "DLHQ-LtpabsS",
        "outputId": "2d714cbb-52b9-44b5-e9d4-ef28b713e84f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Okay, here's a blog post based on the image:\n> \n> ## Meal Prep Magic: From Chaos to Calm (and Deliciousness!)\n> \n> Alright, let's be honest. My relationship with food has been...complicated.  For years, it was either grab whatever's fastest (hello, pizza!) or swing wildly into overly restrictive diets that left me feeling deprived and, frankly, miserable.  Sound familiar?\n> \n> But I'm finally finding my groove, and guess what's been a total game changer? Meal prepping!\n> \n> Just look at this beauty: a perfect, balanced lunch waiting for me. We're talking fluffy rice, vibrant stir-fried red peppers, tender broccoli florets, and savory, marinated chicken. It’s a symphony of textures and flavors, and knowing it’s waiting for me in the fridge keeps me on track, even when those afternoon cravings hit.\n> \n> The first few weeks of meal prepping were a little rough. I experimented with different recipes, messed up cooking times (burnt rice, anyone?), and definitely underestimated the amount of time it would actually take to chop all those veggies. But I kept at it, tweaked my approach, and now, it's a (dare I say it?) enjoyable Sunday ritual.\n> \n> The best part?  Beyond the convenience and the tasty food, I'm actually *enjoying* cooking. I'm learning to appreciate the process, and I feel so much more in control of my eating habits. It's not about deprivation anymore, it's about nourishment and fueling my body with good stuff.\n> \n> So, if you're feeling lost in the food wilderness like I used to, give meal prepping a try! Start small, find a couple of recipes you love, and don't be afraid to experiment. You might just surprise yourself with what you can create, and how much better you feel.\n> \n> What are your favorite meal prep recipes? Share them in the comments below!\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate an Image Caption"
      ],
      "metadata": {
        "id": "eIORG_8GeW9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\",img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-HixUGqheVvY",
        "outputId": "39d4487d-01b3-4056-e922-d4f1d8df3390"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two glass food storage containers hold prepared meals of rice, chicken, broccoli, and peppers. Chopsticks are visible near one of the containers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path = \"/content/drive/MyDrive/data/girl.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Describe this image in detail.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "y3JWyrG-gduV",
        "outputId": "43671081-edea-431a-9d5b-04cc8b9d6141"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a description of the image:\n",
            "\n",
            "The image features a woman with fair skin, dark hair with brown highlights, and a warm, genuine smile. She is dressed in a teal-colored top with small gold-colored floral patterns, which has a shallow V-neckline and three small buttons at the top. Her left arm is bent, and she is pointing her index finger towards the left of the frame. Her right arm is bent and crossed under her left arm. The background is plain white, which makes her the central focus of the image.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Detect Emotions in an image***"
      ],
      "metadata": {
        "id": "NToxndJthZV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"what emotions can you detect in this image?\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "U-YqerCehBWF",
        "outputId": "b2201eb0-143e-42f9-9a03-a6fe649d33e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the image, I can detect the following emotions:\n",
            "\n",
            "*   **Happiness/Joy:** The woman is smiling, which is a clear indicator of happiness or joy.\n",
            "*   **Enthusiasm/Excitement:** The pointing gesture combined with the smile suggests she is excited or enthusiastic about something.\n",
            "*   **Confidence:** Her posture and expression suggest a sense of confidence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Extract Text from an Image**"
      ],
      "metadata": {
        "id": "8UtrBR-WjZaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/data/quote.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extract and read the text from this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "HDsOhmg_hsgF",
        "outputId": "968bb39e-f49b-45b6-ae28-b38306b0a0c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILURE is not the\n",
            "opposite of success\n",
            "it's PART OF\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logo & Product Recognition**"
      ],
      "metadata": {
        "id": "2b0iU2h1Mkc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/logo1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Identify the brand or company associated with this logo.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "SXtDXRCqj4RF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec678fa9-f9f3-43b0-f1f1-300d53ca1ef5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The logo is associated with Amazon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detecting Products from an image**"
      ],
      "metadata": {
        "id": "k85N2SA1OOTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/product.jpg\"\n",
        "image = Image.open(image_path)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"What product is shown in this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "az7xT48hNFZ_",
        "outputId": "6e38431c-4440-4c68-e753-e404e601458e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.  They appear to be wireless, judging by the lack of a visible wire.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Similar Products**"
      ],
      "metadata": {
        "id": "IeYHPAZyPeDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "M4ml8WU0OIYu",
        "outputId": "68278141-cf5d-405a-d3b7-37f53626b038"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones:\n",
            "\n",
            "**Focusing on Style and Features:**\n",
            "\n",
            "* **Other Over-Ear Headphones with Similar Design:** Look for black over-ear headphones with a similar headband style and earcup shape. Many brands (Sony, Bose, Sennheiser, JBL, Audio-Technica) offer similar aesthetics.  Search for terms like \"closed-back headphones,\" \"noise-canceling headphones\" (if that's a desired feature),  or \"premium headphones.\"  Pay attention to images; the overall look is quite similar across many products.\n",
            "\n",
            "* **Wireless vs. Wired:** The picture doesn't definitively show if it's wired or wireless. Consider if you need wireless capabilities (Bluetooth) or prefer a wired connection. This will expand or narrow your search.\n",
            "\n",
            "**Focusing on Price Point:**\n",
            "\n",
            "The image shows a pair of headphones that appear to be mid-range to higher-end in terms of quality.  To find similar products, you will need to decide on a price range.  Search by price and desired features on major online retailers such as Amazon, Best Buy, or directly on the manufacturer's website.\n",
            "\n",
            "\n",
            "**To get more specific recommendations, please provide more details about the desired features, such as:**\n",
            "\n",
            "* **Budget:** How much are you willing to spend?\n",
            "* **Wireless or wired:** Do you need wireless connectivity (Bluetooth)?\n",
            "* **Noise cancellation:** Do you need noise-canceling features?\n",
            "* **Sound quality:** Do you have specific preferences for bass, treble, or overall sound signature?\n",
            "* **Use case:** Will these be used for travel, commuting, at home, gaming, or something else?\n",
            "\n",
            "\n",
            "With more information, I can give more tailored suggestions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/invoice.jpg\"\n",
        "image = Image.open(image_path)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Extract the price from this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nBtuQbTHPrsa",
        "outputId": "774161f5-fdf4-4f4a-f4e0-fa1e62387f1e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The subtotal is $100.00, and the grand total, including 10% tax, is also $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extarct the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "2IygbJcXSQB8",
        "outputId": "1cf5c5c1-5387-4fd9-adf9-91237d500824"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** No discounts are applied.  There is a 10% tax, which is not a discount.  The grand total is the same as the subtotal, implying no discounts were applied to the subtotal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identifying Objects in an image**"
      ],
      "metadata": {
        "id": "TZSA9CloS4fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/bicycle.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "response = model.generate_content([\"Identifying all objects present in this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "DTZ8pw1dSgFi",
        "outputId": "4f3431f9-11c1-489b-df1c-d594df2e71ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects present in the image:\n",
            "\n",
            "* **Two bicycles:** One is black and yellow, the other is white.  Both appear to be adult-sized hybrid or city bikes.\n",
            "* **Two men:**  Riding the bicycles. One is wearing a blue shirt and camouflage shorts; the other is wearing a gray shirt, jeans, and a red cap.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A building:**  A building with a beige facade, a roll-up door, and windows.\n",
            "* **Two chairs:** Visible inside the building through an open doorway.\n",
            "* **A man (in the background):** Sitting in the building's interior.\n",
            "* **Street:** The wet street the cyclists are riding on.\n",
            "* **Vegetation:** Some grass and weeds along the edge of the street.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detecting Multiple Objects & Counting Them**"
      ],
      "metadata": {
        "id": "G94iaNJGT1Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"/content/items.jpg\")\n",
        "\n",
        "response = model.generate_content([\"List all objects in this image and count how many of each are present.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "u_Lc37rYTSWt",
        "outputId": "0e8962d0-988d-4624-a98b-23586d933aa9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a count of the objects in the image:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olives: 2\n",
            "* Fries: 1 (serving)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (bottle/carton)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (shaker)\n",
            "* Sugar: 1 (bowl)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (slices)\n",
            "* Rice: 1 (bowl)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6c2XfOrUXD4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}